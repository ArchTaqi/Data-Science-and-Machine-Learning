{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping [Dublin City Bikes](http://www.dublinbikes.ie/) Data Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.shanelynn.ie/scraping-dublin-city-bikes-data-using-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides a short and simple scraper that queries the Citybik.es API at a predefined rate and stores all of the results into a CSV or SQLite Database file. All data is returned from the API as a JSON dump detailing bike availability at all stations, this data is parsed, converted into a pandas data frame, and inserted into the requested data container. Youâ€™ll need python 2.7, and a few dependencies that are accessible using Pip or easy_install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python City Bikes Scraper\n",
    "#\n",
    "# Simple functions to use the citybik.es API to record bike availability in a specific city.\n",
    "# Settings for scrapers can be changed in lines 18-22\n",
    "# \n",
    "# Built using Python 2.7\n",
    "#\n",
    "# Shane Lynn 24/03/2014\n",
    "# @shane_a_lynn\n",
    "# http://104.236.88.249\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pdsql\n",
    "from time import sleep, strftime, gmtime\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "# define the city you would like to get information from here:\n",
    "# for full list see http://api.citybik.es\n",
    "API_URL = \"http://api.citybik.es/dublinbikes.json\"\n",
    "\n",
    "#Settings:\n",
    "SAMPLE_TIME = 120                   # number of seconds between samples\n",
    "SQLITE = False                      # If true - data is stored in SQLite file, if false - csv.\n",
    "SQLITE_FILE = \"bikedb.db\"           # SQLite file to save data in\n",
    "CSV_FILE = \"output.csv\"             # CSV file to save data in\n",
    "\n",
    "def getAllStationDetails():\n",
    "    print \"\\n\\nScraping at \" + strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
    "\n",
    "    try:\n",
    "        # this url has all the details\n",
    "        decoder = json.JSONDecoder()\n",
    "        station_json = requests.get(API_URL, proxies='')\n",
    "        station_data = decoder.decode(station_json.content)\n",
    "    except:\n",
    "        print \"---- FAIL ----\"\n",
    "        return None\n",
    "\n",
    "    #remove unnecessary data - space saving\n",
    "    # we dont need latitude and longitude\n",
    "    for ii in range(0, len(station_data)):\n",
    "        del station_data[ii]['lat']\n",
    "        del station_data[ii]['lng']\n",
    "        #del station_data[ii]['station_url']\n",
    "        #del station_data[ii]['coordinates']\n",
    "\n",
    "    print \" --- SUCCESS --- \"\n",
    "    return station_data\n",
    "\n",
    "def writeToCsv(data, filename=\"output.csv\"):\n",
    "    \"\"\"\n",
    "    Take the list of results and write as csv to filename.\n",
    "    \"\"\"\n",
    "    data_frame = pd.DataFrame(data)\n",
    "    data_frame['time'] = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
    "    data_frame.to_csv(filename, header=False, mode=\"a\")\n",
    "\n",
    "def writeToDb(data, db_conn):\n",
    "    \"\"\"\n",
    "    Take the list of results and write to sqlite database\n",
    "    \"\"\"\n",
    "    data_frame = pd.DataFrame(data)\n",
    "    data_frame['scrape_time'] = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
    "    pdsql.write_frame(data_frame, \"bikedata\", db_conn, flavor=\"sqlite\", if_exists=\"append\", )\n",
    "    db_conn.commit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create / connect to Sqlite3 database\n",
    "    conn = sqlite3.connect(SQLITE_FILE) # or use :memory: to put it in RAM\n",
    "    cursor = conn.cursor()\n",
    "    # create a table to store the data\n",
    "    cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS bikedata\n",
    "                      (name text, idx integer, timestamp text, number integer,\n",
    "                       free integer, bikes integer, id integer, scrape_time text)\n",
    "                   \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "    #run main function\n",
    "    # we need to run the full collection, parsing, and writing every minute.\n",
    "    while True:\n",
    "        station_data = getAllStationDetails()\n",
    "        if station_data:\n",
    "            if SQLITE:\n",
    "                writeToDb(station_data, conn)\n",
    "            else:                \n",
    "                writeToCsv(station_data, filename=CSV_FILE)\n",
    "\n",
    "        print \"Sleeping for 120 seconds.\"\n",
    "        sleep(120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
